load(".RData")
#PRINT
#PRINT
aaaaaaaaaaa
---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


###########################
# %% install libraries
###########################
# install.packages('glmnet')
# install.packages('csvread')
# install.packages('MASS')
# install.packages('leaps')
# install.packages('grid')
# install.packages('gridExtra')
# install.packages('dplyr')
# install.packages('MatchIt')
# install.packages('gmodels')
# install.packages('tableone')
# install.packages('ggplot2')
# install.packages('survey')
# install.packages('twang')
# install.packages('summarytools')
#  install.packages('Matching')
# install.packages('reshape2')
# install.packages('stddiff')
# install.packages('randomForestSRC')
# install.packages('subgroup.discovery')

###########################
# %% load libraries
###########################
library('glmnet')
library('csvread')
library('MASS')
library('leaps')
library('grid')
library('gridExtra')
library('dplyr')
library('MatchIt')
library('gmodels')
library('tableone')
library('ggplot2')
library('survey')
library('twang')
library('summarytools')
library('Matching')
library('reshape2')
library('stddiff')
library('randomForestSRC')
library('subgroup.discovery')
library(tableone)
library(sandwich)
library(survey)
library("Hmisc")
library("rms")
library(subgroup.discovery)
###########################
# %% setwd
###########################
#setwd("C:/Users/mcschut/Documents/wip/chianti/data/processed/180523/")
#setwd("F:/åå£«/pumc/è¯¾é¢ç»/AMC/Utrecht/NIVEL/Thamar/20180823/")
setwd("H:/qww/AMC/Utrecht/NIVEL/Thamar/20180823/")

setwd("P:/NZR/NZR-001/Innovatieve Onderzoeksmethoden/2. Machine learning antibiotica bij ontstekingen/03. Dataverwerking/4. input R")
###########################
# %% read data and convert variables
###########################

# read in data as factor per default
#data_first_treatment <-read.csv(file = "dummyfile_firsttreatment.csv", na.strings=c("NA","NaN", " ",""), colClasses="factor")
#data_first_treatment<-read.csv(file = "F:/åå£«/pumc/è¯¾é¢ç»/AMC/Utrecht/NIVEL/Thamar/20180523/dummyfile_firsttreatment.csv", na.strings=c("NA","NaN", " ",""), colClasses="factor")
data_first_treatment<-read.csv(file = "H:/qww/AMC/Utrecht/NIVEL/Thamar/20180523/researchfile_firsttreatment.csv", na.strings=c("NA","NaN", " ",""), colClasses="factor")

data_first_treatment <-read.csv(file = "researchfile_firsttreatment.csv", na.strings=c("NA","NaN", " ",""), colClasses="factor")


#####################
setwd("P:/NZR/NZR-001/Innovatieve Onderzoeksmethoden/2. Machine learning antibiotica bij ontstekingen/03. Dataverwerking/6. output R/20181002TvE/")
### Provide descriptives of all variables
z<-dfSummary(data_first_treatment)
write.table(z, file="descriptives_raw.csv", sep = ",")
# weird table layout oin excel (//)

# convert selected variables to numeric
cols.num <- c("age","nr_chron3", 'practice_size', 'nr_medication','nr_contacts_infection','nr_prescriptions_AB' ,'nr_contacts_resp')
data_first_treatment[cols.num] <- sapply(data_first_treatment[cols.num],as.numeric)

###########################
# %% select variables
###########################

setwd("P:/NZR/NZR-001/Innovatieve Onderzoeksmethoden/2. Machine learning antibiotica bij ontstekingen/03. Dataverwerking/4. input R")

vars_selected <-read.csv(file = "variable_selections.csv",sep=';')

vars_treatment   <- as.character(filter(vars_selected,treatment == 1)$variable)
vars_outcome     <- as.character(filter(vars_selected,outcome == 1)$variable)
vars_other       <- as.character(filter(vars_selected,other == 1)$variable)
vars_relevant    <- as.character(filter(vars_selected,relevant == 1)$variable)
vars_relevant_nto    <- as.character(filter(vars_selected,relevant_nto == 1)$variable)

###########################
# %% drop variables that were indicated as irrelevant
###########################
data_first_treatment_relevant <- select(data_first_treatment,vars_relevant)

###########################
# %% drop variables with missing values
###########################

# select only variables with percentage missings less than threshold
data_first_treatment_relevant_0.4 <- data_first_treatment_relevant[, colMeans(is.na(data_first_treatment_relevant)) <= 0.4]

# FYI what were the dropped variables?
  setdiff(vars_selected$variable,names(data_first_treatment_relevant_0.4))
# only CRP due to missings, other dropped variables are not relevant

# remove dropped variables from variable selection
vars_relevant_0.4 <- intersect(vars_relevant,names(data_first_treatment_relevant_0.4))

###########################
# %% descriptive statistics and remove variables with variance = 0 @@@ still gives warning messages about deprecated
###########################
# TvE: tried two alternatives, both resulted in no variabels with variance ==0. Checked in stata --> same result

# which variables have variance = 0?
# vars_zero = lapply(data_first_treatment_relevant_0.4, var, na.rm = TRUE) != 0
# vars_zero_names = names(vars_zero[vars_zero == FALSE])
all(duplicated(data_first_treatment_relevant_0.4)[-1L])
which(apply(data_first_treatment_relevant_0.4, 2, var) == 0)

# drop variables with variance = 0
#data_first_treatment_relevant_0.4_v0<- dplyr::select(data_first_treatment_relevant_0.4,-vars_zero_names)

# remove dropped variables from variable selection
#vars_relevant_0.4_v0 <- intersect(vars_relevant,names(data_first_treatment_relevant_0.4_v0)) 


###########################
# %% remove rows with any missing values
###########################

# FYI how many rows are deleted (~10000)
dim(data_first_treatment_relevant_0.4)[1] - dim(na.omit(data_first_treatment_relevant_0.4))[1]

data_first_treatment_relevant_0.4_na.omit <- na.omit(data_first_treatment_relevant_0.4)

vars_relevant_0.4_na.omit <- names(data_first_treatment_relevant_0.4_na.omit)
# TvE: what happens here? (above, nothing?)

###########################
# %% descriptive statistics and remove variables with variance = 0 @@@ still gives warning messages about deprecated
# TvE: this is a duplication of lines 131 and further, should be removed?
###########################

# which variables have variance = 0?
#vars_zero_na.omit = lapply(data_first_treatment_relevant_0.4_v0_na.omit, var, na.rm = TRUE) != 0
#vars_zero_na.omit_names = names(vars_zero_na.omit[vars_zero_na.omit == FALSE])
#all(duplicated(x)[-1L])

# drop variables with variance = 0
#data_first_treatment_relevant_0.4_na.omit_v0<- dplyr::select(data_first_treatment_relevant_0.4_v0_na.omit,-vars_zero_na.omit_names)

# remove dropped variables from variable selection
#vars_relevant_0.4_na.omit_v0 <- intersect(vars_relevant,names(data_first_treatment_relevant_0.4_v0_na.omit)) 



###########################
# %% print table one
###########################
setwd("P:/NZR/NZR-001/Innovatieve Onderzoeksmethoden/2. Machine learning antibiotica bij ontstekingen/03. Dataverwerking/6. output R/20181002TvE/")

a<-print(CreateTableOne(vars=names(data_first_treatment_relevant_0.4),
                     strata="AB_nose_infection",
                     data=data_first_treatment_relevant_0.4[,names(data_first_treatment_relevant_0.4) %in% vars_relevant_0.4, drop = F],
                     test=TRUE))

b<-print(CreateTableOne(vars=names(data_first_treatment_relevant_0.4),
                        strata="type_AB_nose",
                        data=data_first_treatment_relevant_0.4[,names(data_first_treatment_relevant_0.4) %in% vars_relevant_0.4, drop = F],
                        test=TRUE))

# TvE added 'c' to test shorter code (result: c=b)                        
#c<-print(CreateTableOne(vars=names(data_first_treatment_relevant_0.4),
                        strata="type_AB_nose",
                        data=data_first_treatment_relevant_0.4,
                        test=TRUE))
 
write.table(a, file="Unmatched_ab.csv", sep = ",")
write.table(b, file="Unmatched_type.csv", sep = ",")
#write.table(c, file="Unmatched_type_test.csv", sep = ",")


###########################
# %% STEP 1: select variables with OR > 1%
###########################
# TVE: added 'link=logit' to first calculation (did not cause any differences)
# conclusion: no variables change the OR by more than ~1% so no confounders selected in this step

# calculate OR1
model_OR <-glm(
  outcome_4 ~ AB_nose_infection,
  family = binomial(link=logit),
  data = data_first_treatment_relevant_0.4)
OR1<- exp(model_OR$coefficients[2])

# FYI model summary
summary(model_OR)

# calculate rates for relevant variables
# TVE: vars you don't want to include here
vars_relevant_0.4_nto <- vars_relevant_0.4[!vars_relevant_0.4%in% c("outcome_4","AB_nose_infection","type_AB_nose")]

rate <- sapply(vars_relevant_0.4_nto,
       function(varname){
         md <-glm(
                as.formula(paste("outcome_4 ~ AB_nose_infection + ",varname)),
                family=binomial(link=logit),
                data=data_first_treatment_relevant_0.4
              )
         rate <- abs(exp(summary(md)$coef[2])-OR1)/OR1
       }
     )

# drop the variables that have OR =< 1%
vars_OR <- labels(rate)[unlist(rate)> 0.01]

# drop ".AB_nose_infection1" from labels
vars_OR <- gsub(".AB_nose_infection1", "", vars_OR)

###########################
# %% STEP 2: AIC to select co-variables: outcome
###########################
```{r}

model_AICo <- glm(
  outcome_4 ~ .,
  data = dplyr::select(data_first_treatment_relevant_0.4_na.omit, - vars_treatment),
  family=binomial)

# Select most predictive variables
AICo <- stepAIC(model_AICo)


# FYI show formula of the final model
formula(AICo)

# show the selected variables
vars_AICo <- attr(terms(AICo),"term.labels")
```


###########################
# %% STEP 3: AIC to select co-variables: treatment
###########################
```{r}
model_AICt <- glm(
  AB_nose_infection ~ .,
  data = select(data_first_treatment_relevant_0.4_na.omit[!names(data_first_treatment_relevant_0.4_na.omit) %in% vars_outcome],- type_AB_nose),
  family=binomial)

# Select most predictive variables
AICt <- stepAIC(model_AICt)

# FYI show formula of the final model
formula(AICt)

# Show the selected variables
vars_AICt <- attr(terms(AICt),"term.labels")
```

###########################
# %% Step 4 univariate relation outcome ~ selected treatment variables
###########################
```{r}
models <- lapply(vars_AICt,
  function(x) {
    glm(substitute(outcome_4 ~ i, list(i = as.name(x))),
        family = binomial,
        data = select(data_first_treatment_relevant_0.4_na.omit,-vars_treatment))
  }
)

lapply(models, summary)

```
# try logistic uni& multivariate to select confounders

```{r}
#### logistic univariate
uni<-glm(outcome_4~AB_nose_infection, data= data_first_treatment_relevant_0.4, family = binomial)

summary(uni)



#### logistic multivariate
multicov <-glm(
            as.formula(paste("outcome_4 ~ AB_nose_infection + ", paste(vars_relevant_nto, collapse="+"),sep="")),
            family = "binomial",
            data = data_first_treatment_relevant_0.4
           )

summary(multicov)

```
###########################
# %% Determine confounder variables @@@ todo ask ameen how we do this

# TVE: I think that the confounders that resulted form step 1 (OR) are missing? nr_contacts_infectino and nr_prescriptions_AB? (nr_contacts_resp and nr_medications are included through AICo)
# Added manually (last two lines) --> omitted after email from AmeeN: 1% change is not enough (standaard is 10%)
###########################

vars_confounders = c(
  "age",
  "sex",
  "nr_medication",
  "COPD_morb",
  "migraine_morb",
  "hartfalen_morb",
  "nr_contacts_resp",
  "osteop_morb",
  "poor_immune_response",
  "alcmisb_morb",
  "postalcode")
  
data_confounders_to_nao <- data_first_treatment_relevant_0.4_na.omit[c(
"outcome_4","AB_nose_infection","type_AB_nose", 
  "age",
  "sex",
  "nr_medication",
  "COPD_morb",
  "migraine_morb",
  "hartfalen_morb",
  "nr_contacts_resp",
  "osteop_morb",
  "poor_immune_response",
  "alcmisb_morb",
  "postalcode")]
  
  data_confounders_to <- data_first_treatment_relevant[c(
"outcome_4","AB_nose_infection","type_AB_nose", 
  "age",
  "sex",
  "nr_medication",
  "COPD_morb",
  "migraine_morb",
  "hartfalen_morb",
  "nr_contacts_resp",
  "osteop_morb",
  "poor_immune_response",
  "alcmisb_morb",
  "postalcode")]

###########################
# %% Propensity score matching with ps
###########################
```{r}
data_confounders_to$AB<-0
data_confounders_to$AB[as.numeric(data_confounders_to$AB_nose_infection)==2]<-1
#data_confounders_to$AB[as.numeric(data_confounders_to$AB_nose_infection)==1]<-0

set.seed(1)
PS_Model<-ps(
  as.formula(paste("AB ~ ",paste(vars_confounders,collapse="+"),sep="")),
  data = data_confounders_to,
  verbose = FALSE, 
  estimand = "ATE")

#plot(PS_Model, plots = 1)
#plot(PS_Model, plots = 2)
#plot(PS_Model, plots = 3)
#plot(PS_Model, plots = 4)
#plot(PS_Model, plots = 5)

summary(PS_Model$gbm.obj,
        n.trees=PS_Model$desc$ks.mean.ATE$n.trees,
        plot=TRUE)
summary(PS_Model)
ps.balance<-bal.table(PS_Model)
ps.balance

data_confounders_to$w<- get.weights(PS_Model,stop.method = "es.mean" )


design.ps <- svydesign(ids=~1, weights = ~ w, data = data_confounders_to)
#svychisq(~outcome_4 + AB_nose_infection, design = design.ps)

## survey
# model 1
glm_cto_ab <- svyglm(outcome_4 ~ AB_nose_infection, design = design.ps, family=quasibinomial)

summary(glm_cto_ab)

cbind( exp(coef(glm_cto_ab)), exp(summary(glm_cto_ab)$coefficients[,1] - 1.96*summary(glm_cto_ab)$coefficients[,2]), exp(summary(glm_cto_ab)$coefficients[,1] + 1.96*summary(glm_cto_ab)$coefficients[,2]) )

# model 2
glm_cto_ab_postcode <- svyglm(outcome_4 ~ AB_nose_infection + postalcode, design = design.ps, family=quasibinomial)

summary(glm_cto_ab_postcode)

cbind( exp(coef(glm_cto_ab_postcode)), exp(summary(glm_cto_ab_postcode)$coefficients[,1] - 1.96*summary(glm_cto_ab_postcode)$coefficients[,2]), exp(summary(glm_cto_ab_postcode)$coefficients[,1] + 1.96*summary(glm_cto_ab_postcode)$coefficients[,2]) )

# model 3
glm_cto_ab_confounder <- svyglm(
as.formula(paste("outcome_4 ~ AB_nose_infection +",paste(vars_confounders,collapse="+"),sep="")), 
                     design = design.ps, family=quasibinomial)

summary(glm_cto_ab_confounder)

cbind( exp(coef(glm_cto_ab_confounder)), exp(summary(glm_cto_ab_confounder)$coefficients[,1] - 1.96*summary(glm_cto_ab_confounder)$coefficients[,2]), exp(summary(glm_cto_ab_confounder)$coefficients[,1] + 1.96*summary(glm_cto_ab_confounder)$coefficients[,2]) )
```

###########################
# %% GLM before matching
###########################
#### logistic univariate
```{r}
uni<-glm(outcome_4~AB_nose_infection, data= data_first_treatment_relevant_0.4, family = binomial)

summary(uni)

# TvE I don't understand the (purpose of the) next command
cbind( exp(coef(uni)), exp(summary(uni)$coefficients[,1] - 1.96*summary(uni)$coefficients[,2]), exp(summary(uni)$coefficients[,1] + 1.96*summary(uni)$coefficients[,2]) )
```



#### logistic multivariate
```{r}
unicov <-glm(
            as.formula(paste("outcome_4 ~ AB_nose_infection + ", paste(vars_confounders, collapse="+"),sep="")),
            family = "binomial",
            data = data_first_treatment_relevant_0.4
           )

summary(unicov)
cbind( exp(coef(unicov)), exp(summary(unicov)$coefficients[,1] - 1.96*summary(unicov)$coefficients[,2]), exp(summary(unicov)$coefficients[,1] + 1.96*summary(unicov)$coefficients[,2]) )
```

###########################
## Type AB analysis 
```{r}
plot(data_first_treatment_relevant_0.4$type_AB_nose)

table(data_first_treatment_relevant_0.4$type_AB_nose)
```

### Testing before mnps
#### logistic univariate
```{r}
uni_type<-glm(outcome_4 ~ factor(type_AB_nose), data= data_first_treatment_relevant_0.4, family = binomial)

summary(uni_type)

cbind( exp(coef(uni_type)), exp(summary(uni_type)$coefficients[,1] - 1.96*summary(uni_type)$coefficients[,2]), exp(summary(uni_type)$coefficients[,1] + 1.96*summary(uni_type)$coefficients[,2]) )
```


#### logistic multivariate
```{r}
multi_type <-glm(
              as.formula(paste("outcome_4 ~ type_AB_nose + ", paste(vars_confounders, collapse="+"),sep="")),
              family = "binomial", data= data_first_treatment_relevant_0.4) 

summary(multi_type)

cbind( exp(coef(multi_type)), exp(summary(multi_type)$coefficients[,1] - 1.96*summary(multi_type)$coefficients[,2]), exp(summary(multi_type)$coefficients[,1] + 1.96*summary(multi_type)$coefficients[,2]) )
```


###########################ctor
# %% running of multinomial propensity scores
###########################
```{r}

MNPS_cto_type <- mnps(
  as.formula(paste("type_AB_nose ~ ",paste(vars_confounders,collapse="+"),sep="")),
  data = data_confounders_to,
  estimand = "ATE",
  verbose = FALSE,
  stop.method = c("es.mean", "ks.mean"),
  n.trees = 5000)

summary(MNPS_cto_type)

plot(MNPS_cto_type, plots = 1) 
plot(MNPS_cto_type, plots = 2, subset = "es.mean")
plot(MNPS_cto_type, plots = 3) 
#Warning message:
#In plot.mnps(MNPS_cto_type, plots = 3) :
  #Some effect sizes are larger than 3 and may not have been plotted.
plot(MNPS_cto_type, plots = 4) 
data_confounders_to$w <- get.weights(MNPS_cto_type, stop.method = "es.mean")

design.mnps <- svydesign(ids=~1, weights=~w, data=data_confounders_to) 
## survey
# model1
glm_cto <- svyglm(outcome_4 ~ type_AB_nose, design = design.mnps,family=quasibinomial)

summary(glm_cto)

cbind( exp(coef(glm_cto)), exp(summary(glm_cto)$coefficients[,1] - 1.96*summary(glm_cto)$coefficients[,2]), exp(summary(glm_cto)$coefficients[,1] + 1.96*summary(glm_cto)$coefficients[,2]) )

```

###########################
# ITE
# %% synthetic random forest
###########################
```{r}
### treatment using subset data with only no treatment AB 
AB_0 <- data_first_treatment_relevant_0.4%>% filter (type_AB_nose == 0) ## control

regF_0 <- rfsrcSyn(
as.formula(paste("outcome_4 ~ ", paste(vars_confounders, collapse="+"),sep="")),
 data  = AB_0)

### using that syntetic forest to predict outcome of all participants (so wether they had treatment of not)
pred.Syn_type_0 <- rfsrcSyn(object = regF_0, newdata = data_first_treatment_relevant_0.4 )

```
```{r}
### treatment using subset data with treatment AB 
AB_1 <- data_first_treatment_relevant_0.4%>% filter (AB_nose_infection == 1)

regF_1 <- rfsrcSyn(
  as.formula(paste("outcome_4 ~ ", paste(vars_confounders, collapse="+"),sep="")),
  data  = AB_1)
  
pred.Syn_AB_1 <- rfsrcSyn(object = regF_1, newdata = data_first_treatment_relevant_0.4)

# calculate difference
data_first_treatment_relevant_0.4$delta <- (pred.Syn_AB_1$rfSynPred$predicted -  pred.Syn_type_0$rfSynPred$predicted)[,2]


fit <- glm(
  as.formula(paste("delta ~ ", paste(vars_confounders, collapse="+"),sep="")),
  data  = data_first_treatment_relevant_0.4, family = gaussian)

fit_delta<- summary(fit)
fit_delta

  variable <- names(fit$coefficients)
  coef <- coef(fit_delta)[,1]
  p_value <- coef(fit_delta)[,4]
  
  table_AB = data.frame(variable, coef, p_value)
  write.csv(table_AB, file='fit_delta.csv')

```


###loop for type 1-5

for (j in 1:5) {
  
  AB_j <- data_first_treatment_relevant_0.4%>% filter (type_AB_nose == j)
  
  regF_j <- rfsrcSyn(
  as.formula(paste("outcome_4 ~ ", paste(vars_confounders, collapse="+"),sep="")),
  data  = AB_j)
  
  pred.Syn_type_j <- rfsrcSyn(object = regF_j, newdata = data_first_treatment_relevant_0.4)
  # calculate difference
  data_first_treatment_relevant_0.4$delta_j <- (pred.Syn_type_j$rfSynPred$predicted -  pred.Syn_type_0$rfSynPred$predicted)[,2]
  
  
  fit_j <- glm(
  as.formula(paste(" delta_j ~ ", paste(vars_confounders, collapse="+"),sep="")),
  data  = data_first_treatment_relevant_0.4, family = gaussian)
  fit_delta_j<- summary(fit_j)
  
  variable <- names(fit_j$coefficients)
  coef <- coef(fit_delta_j)[,1]
  p_value <- coef(fit_delta_j)[,4]
  
  table = data.frame(variable, coef, p_value)
  write.csv(table, file=sprintf('fit_delta_%s.csv',j))
# write.csv(table, file=sprintf('H:/qww/AMC/Utrecht/NIVEL/Thamar/20180823/fit_delta_%s.csv',j))
  
  data_first_treatment_relevant_0.4[,ncol(data_first_treatment_relevant_0.4)+1]<-data_first_treatment_relevant_0.4$delta_j
  names(data_first_treatment_relevant_0.4)[ncol(data_first_treatment_relevant_0.4)]<-paste0("delta_",j)
}


###########################
# %% model validation 
###########################

```{r}

## test-set performance

set.seed(2)
train<-sample(1:nrow(data_first_treatment_relevant_0.4_na.omit),0.8*nrow(data_first_treatment_relevant_0.4_na.omit))
data_first_treatment_relevant_0.4_na.omit.train<-data_first_treatment_relevant_0.4_na.omit[train,]
class(data_first_treatment_relevant_0.4_na.omit.train)

data_first_treatment_relevant_0.4_na.omit.test<-data_first_treatment_relevant_0.4_na.omit[-train,]
outcome_4.test<-data_first_treatment_relevant_0.4_na.omit$outcome_4[-train]  

### Build SRF model in train subset, predic SRF model in test subset

regF <- rfsrcSyn(
  as.formula(paste("outcome_4 ~ ", paste(vars_confounders, collapse="+"),sep="")),
  data  = data_first_treatment_relevant_0.4_na.omit.train)

### using that synthetic forest to predict outcome of test participants (so wether they had treatment of not)
pred.Syn <- rfsrcSyn(object = regF, newdata = data_first_treatment_relevant_0.4_na.omit.test)


pred<- pred.Syn$ rfSynPred$predicted
data_first_treatment_relevant_0.4_na.omit$pred_truetreatment<- ifelse(data_first_treatment_relevant_0.4_na.omit$AB_nose_infection == 1,pred[1], pred[0])

sum(data_first_treatment_relevant_0.4_na.omit$pred_truetreatment, na.rm=TRUE)


plsmo(pred_truetreatment,data_first_treatment_relevant_0.4_na.omit$AB_nose_infection == 1, xlab="predictions", ylab="% events") # This is a smoother and gives the calibration graph. The default of smoothing window is 2/3. Calibration is not bad.
plsmo(pred_truetreatment,data_first_treatment_relevant_0.4_na.omit$AB_nose_infection == 1, xlab="predictions", ylab="% events", f=1/3) # bumpy

plsmo(pred_truetreatment, data_first_treatment_relevant_0.4_na.omit$AB_nose_infection == 1, xlab="predictions", ylab="% events", group = data_first_treatment_relevant_0.4_na.omit$age > median(data_first_treatment_relevant_0.4_na.omit$age)) # check per group (here above and below median BMI)
# how to define imaginary line vs full line???

range(pred_truetreatment, na.rm=TRUE) # very good range but let's also look now at distribution of predicitons:
plsmo(pred_truetreatment, data_first_treatment_relevant_0.4_na.omit$AB_nose_infection == 1, xlab="predictions", ylab="% events", datadensity=T, na.rm=TRUE) # you need to zoom in on the graph to see the tick marks
hist(pred_truetreatment) # or just use a histogram


data_first_treatment_relevant_0.4_na.omit.test$OutcomeCstat<-0
data_first_treatment_relevant_0.4_na.omit$treatCstat[as.numeric(data_first_treatment_relevant_0.4_na.omit$AB_nose_infection)==2]<-1
data_first_treatment_relevant_0.4_na.omit$treatCstat[as.numeric(data_first_treatment_relevant_0.4_na.omit$AB_nose_infection)==1]<-0

somers2(as.numeric(pred[,2]),as.numeric(data_first_treatment_relevant_0.4_na.omit.test$treatCstat))

  
auc <- somers2(pred_truetreatment, data_first_treatment_relevant_0.4_na.omit$treatCstat, na.rm = TRUE )  
(auc <- somers2(pred_truetreatment, data_first_treatment_relevant_0.4_na.omit$AB_nose_infection )["C"]) # this is the same as somers2(predictions, pima$testC == 1)["C"] but more compact
brier   <- mean((pred_t1-data_first_treatment_relevant_0.4_na.omit$AB_nose_infection)^2)


# Let us get unbiased estimates of the performance
dd <- datadist(data_first_treatment_relevant_0.4_na.omit)  ###how to explain???
options(datadist='dd')

model <- lrm( as.formula(paste("outcome_4 ~ ", paste(vars_confounders, collapse="+"),sep="")), x=T, y=T, data=data_first_treatment_relevant_0.4_na.omit)
v <- validate(model, method="boot", B=100, pr=F)
v # look at table of (bias corrected) performance measure
v[1,5] # This is the adjusted Dxy
v[1,5]/2 + 0.5 # and this is the AUC
#write.csv(pimaWithout, file="MyFile.csv")

```


###########################
# %% subgroup analysis
###########################


```{r}
# PRIM with delta coming from binary AB
PRIM <- subset(data_first_treatment_relevant_0.4_na.omit, select = c(age, nr_medication, kanker_morb, coronhartz_morb,  RA_morb , alcmisb_morb ,
                                           COPD_morb, hartritme_morb, migraine_morb,   nr_prescriptions_AB, nr_chron3,practice_size,chrnek_morb ,hartfalen_morb, delta))
prim.table<-data.frame(matrix(ncol=(6)))
colnames(prim.table)<-c("alpha","beta","number_cov","rule_cov","number_div","rule_div")

set.seed(1234)

for (i in 1:10){
  alpha<-i/100
  for (j in 1:10){
    beta<-j/100
    p.cov<-subgroup.discovery::prim.cover(delta~., data = PRIM,
                                          peeling.quantile=alpha,
                                          min.support=beta, 
                                          plot= FALSE, 
                                          optimal.box= "2se")
    rule_cov<-p.cov$covers[[1]]$superrule
    p.div <- prim.diversify(delta ~ .,
                                      data = PRIM,
                                      n = 4,
                                      peeling.quantile = alpha,
                                      min.support = beta,
                                      plot = FALSE,
                                      optimal.box = "2se")
    rule_div<-p.div$attempts[[1]]$superrule
    
    prim.table[10*i+j-10,]<-c(alpha,beta,length(rule_cov),toString(rule_cov),length(rule_div),toString(rule_div))
    
  }
}

# PRIM with delta coming from  AB TYPE 0 VS 1
PRIM_1 <- subset(data_first_treatment_relevant_0.4_na.omit, select = c(age, nr_medication, kanker_morb, coronhartz_morb,  RA_morb , alcmisb_morb ,
                                           COPD_morb, hartritme_morb, migraine_morb,   nr_prescriptions_AB, nr_chron3,practice_size,chrnek_morb ,hartfalen_morb, delta_1))
prim.table_1<-data.frame(matrix(ncol=(6)))
colnames(prim.table_1)<-c("alpha","beta","number_cov","rule_cov","number_div","rule_div")

set.seed(1234)

for (i in 1:10){
  alpha<-i/100
  for (j in 1:10){
    beta<-j/100
    p.cov<-subgroup.discovery::prim.cover(delta_1~., data = PRIM_1,
                                          peeling.quantile=alpha,
                                          min.support=beta, 
                                          plot= FALSE, 
                                          optimal.box= "2se")
    rule_cov<-p.cov$covers[[1]]$superrule
    p.div <- prim.diversify(delta_1 ~ .,
                                      data = PRIM_1,
                                      n = 4,
                                      peeling.quantile = alpha,
                                      min.support = beta,
                                      plot = FALSE,
                                      optimal.box = "2se")
    rule_div<-p.div$attempts[[1]]$superrule
    
    prim.table_1[10*i+j-10,]<-c(alpha,beta,length(rule_cov),toString(rule_cov),length(rule_div),toString(rule_div))
    
  }
}

# PRIM with delta coming from  AB TYPE 0 VS 2
PRIM_2 <- subset(data_first_treatment_relevant_0.4_na.omit, select = c(age, nr_medication, kanker_morb, coronhartz_morb,  RA_morb , alcmisb_morb ,
                                           COPD_morb, hartritme_morb, migraine_morb,   nr_prescriptions_AB, nr_chron3,practice_size,chrnek_morb ,hartfalen_morb, delta_2))
prim.table_2<-data.frame(matrix(ncol=(6)))
colnames(prim.table_2)<-c("alpha","beta","number_cov","rule_cov","number_div","rule_div")

set.seed(1234)

for (i in 1:10){
  alpha<-i/100
  for (j in 1:10){
    beta<-j/100
    p.cov<-subgroup.discovery::prim.cover(delta_2~., data = PRIM_2,
                                          peeling.quantile=alpha,
                                          min.support=beta, 
                                          plot= FALSE, 
                                          optimal.box= "2se")
    rule_cov<-p.cov$covers[[1]]$superrule
    p.div <- prim.diversify(delta_2 ~ .,
                                      data = PRIM_2,
                                      n = 4,
                                      peeling.quantile = alpha,
                                      min.support = beta,
                                      plot = FALSE,
                                      optimal.box = "2se")
    rule_div<-p.div$attempts[[1]]$superrule
    
    prim.table_2[10*i+j-10,]<-c(alpha,beta,length(rule_cov),toString(rule_cov),length(rule_div),toString(rule_div))
    
  }
}

# PRIM with delta coming from  AB TYPE 0 VS 3
PRIM_3 <- subset(data_first_treatment_relevant_0.4_na.omit, select = c(age, nr_medication, kanker_morb, coronhartz_morb,  RA_morb , alcmisb_morb ,
                                           COPD_morb, hartritme_morb, migraine_morb,   nr_prescriptions_AB, nr_chron3,practice_size,chrnek_morb ,hartfalen_morb, delta_3))
prim.table_3<-data.frame(matrix(ncol=(6)))
colnames(prim.table_3)<-c("alpha","beta","number_cov","rule_cov","number_div","rule_div")

set.seed(1234)

for (i in 1:10){
  alpha<-i/100
  for (j in 1:10){
    beta<-j/100
    p.cov<-subgroup.discovery::prim.cover(delta_3~., data = PRIM_3,
                                          peeling.quantile=alpha,
                                          min.support=beta, 
                                          plot= FALSE, 
                                          optimal.box= "2se")
    rule_cov<-p.cov$covers[[1]]$superrule
    p.div <- prim.diversify(delta_3 ~ .,
                                      data = PRIM_3,
                                      n = 4,
                                      peeling.quantile = alpha,
                                      min.support = beta,
                                      plot = FALSE,
                                      optimal.box = "2se")
    rule_div<-p.div$attempts[[1]]$superrule
    
    prim.table_3[10*i+j-10,]<-c(alpha,beta,length(rule_cov),toString(rule_cov),length(rule_div),toString(rule_div))
    
  }
}

# PRIM with delta coming from  AB TYPE 0 VS 4
PRIM_4 <- subset(data_first_treatment_relevant_0.4_na.omit, select = c(age, nr_medication, kanker_morb, coronhartz_morb,  RA_morb , alcmisb_morb ,
                                           COPD_morb, hartritme_morb, migraine_morb,   nr_prescriptions_AB, nr_chron3,practice_size,chrnek_morb ,hartfalen_morb, delta_4))
prim.table_4<-data.frame(matrix(ncol=(6)))
colnames(prim.table_4)<-c("alpha","beta","number_cov","rule_cov","number_div","rule_div")

set.seed(1234)

for (i in 1:10){
  alpha<-i/100
  for (j in 1:10){
    beta<-j/100
    p.cov<-subgroup.discovery::prim.cover(delta_4~., data = PRIM_4,
                                          peeling.quantile=alpha,
                                          min.support=beta, 
                                          plot= FALSE, 
                                          optimal.box= "2se")
    rule_cov<-p.cov$covers[[1]]$superrule
    p.div <- prim.diversify(delta_4 ~ .,
                                      data = PRIM_4,
                                      n = 4,
                                      peeling.quantile = alpha,
                                      min.support = beta,
                                      plot = FALSE,
                                      optimal.box = "2se")
    rule_div<-p.div$attempts[[1]]$superrule
    
    prim.table_4[10*i+j-10,]<-c(alpha,beta,length(rule_cov),toString(rule_cov),length(rule_div),toString(rule_div))
    
  }
}

```









